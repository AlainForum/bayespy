@ARTICLE{Luttinen:2010,
  author = {Luttinen, Jaakko and Ilin, Alexander},
  title = {Transformations in variational {Bayesian} factor analysis to speed
        up learning},
  journal = {Neurocomputing},
  year = {2010},
  volume = {73},
  pages = {1093--1102},
  abstract = {We propose simple transformation of the hidden states in variational
        Bayesian factor analysis models to speed up the learning procedure.
        The speed-up is achieved by using proper parameterization of the
        posterior approximation which allows joint optimization of its individual
        factors, thus the transformation is theoretically justified. We derive
        the transformation formulae for variational Bayesian factor analysis
        and show experimentally that it can significantly improve the rate
        of convergence. The proposed transformation basically performs centering
        and whitening of the hidden factors taking into account the posterior
        uncertainties. Similar transformations can be applied to other variational
        Bayesian factor analysis models as well.},
  doi = {10.1016/j.neucom.2009.11.018}
}

@INCOLLECTION{Luttinen:2013,
  author = {Luttinen, Jaakko},
  title = {Fast Variational {Bayesian} Linear State-Space Model},
  booktitle = {Machine Learning and Knowledge Discovery in Databases},
  publisher = {Springer},
  year = {2013},
  editor = {Blockeel, Hendrik and Kersting, Kristian and Nijssen, Siegfried and
        Železný, Filip},
  volume = {8188},
  series = {Lecture Notes in Computer Science},
  pages = {305--320},
  abstract = {This paper presents a fast variational Bayesian method for linear
        state-space models. The standard variational Bayesian expectation-maximization
        (VB-EM) algorithm is improved by a parameter expansion which optimizes
        the rotation of the latent space. With this approach, the inference
        is orders of magnitude faster than the standard method. The speed
        of the proposed method is demonstrated on an artificial dataset and
        a large real-world dataset, which shows that the standard VB-EM algorithm
        is not suitable for large datasets because it converges extremely
        slowly. In addition, the paper estimates the temporal state variables
        using a smoothing algorithm based on the block LDL decomposition.
        This smoothing algorithm reduces the number of required matrix inversions
        and avoids a model augmentation compared to previous approaches.},
  doi = {10.1007/978-3-642-40988-2_20}
}

@INCOLLECTION{Luttinen:2014,
  author = {Luttinen, Jaakko and Raiko, Tapani and Ilin, Alexander},
  title = {Linear State-Space Model with Time-Varying Dynamics},
  booktitle = {Machine Learning and Knowledge Discovery in Databases},
  publisher = {Springer},
  year = {2014},
  editor = {Calders, Toon and Esposito, Floriana and H\"ullermeier, Eyke and Meo, Rosa},
  volume = {???},
  series = {Lecture Notes in Computer Science},
  pages = {???--???},
  abstract = {???},
  doi = {???}
}
